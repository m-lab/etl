total_storage_limit: 100M

queue:
# TODO(dev): delete this queue
- name: etl-parser-queue
  target: etl-parser
  # Average rate at which to release tasks to the service.  Default is 5/sec
  # This is actually the rate at which tokens are added to the bucket.
  rate: 5/s
  # Number of tokens that can accumulate in the bucket.  Default is 5.  This should
  # have very little impact for our environment.
  bucket_size: 50
  # Maximum number of concurrent requests.  This is large now, until we address the
  # latency associated with BQ inserts.
  max_concurrent_requests: 500

- name: etl-ndt-queue
  target: ndt-parser
  # Average rate at which to release tasks to the service.  Default is 5/sec
  # This is actually the rate at which tokens are added to the bucket.
  rate: 5/s
  # Number of tokens that can accumulate in the bucket.  Default is 5.  This should
  # have very little impact for our environment.
  bucket_size: 50
  # Maximum number of concurrent requests.  This is large now, until we address the
  # latency associated with BQ inserts.
  max_concurrent_requests: 500

- name: etl-traceroute-queue
  target: traceroute-parser
  # Average rate at which to release tasks to the service.  Default is 5/sec
  # This is actually the rate at which tokens are added to the bucket.
  rate: 5/s
  # Number of tokens that can accumulate in the bucket.  Default is 5.  This should
  # have very little impact for our environment.
  bucket_size: 50
  # Maximum number of concurrent requests.  This is large now, until we address the
  # latency associated with BQ inserts.
  max_concurrent_requests: 500

- name: etl-sidestream-queue
  target: sidestream-parser
  # Average rate at which to release tasks to the service.  Default is 5/sec
  # This is actually the rate at which tokens are added to the bucket.
  rate: 5/s
  # Number of tokens that can accumulate in the bucket.  Default is 5.  This should
  # have very little impact for our environment.
  bucket_size: 50
  # Maximum number of concurrent requests.  This is large now, until we address the
  # latency associated with BQ inserts.
  max_concurrent_requests: 500

- name: etl-disco-queue
  target: disco-parser
  # Average rate at which to release tasks to the service.  Default is 5/sec
  # This is actually the rate at which tokens are added to the bucket.
  rate: 5/s
  # Number of tokens that can accumulate in the bucket.  Default is 5.  This should
  # have very little impact for our environment.
  bucket_size: 50
  # Maximum number of concurrent requests.  This is large now, until we address the
  # latency associated with BQ inserts.
  max_concurrent_requests: 500
