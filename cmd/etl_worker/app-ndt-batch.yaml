# Should be auto-deployed to sandbox and staging.
# Use github release to trigger deployment to prod.

runtime: custom
env: flex
service: etl-ndt-batch-parser

# Resource and scaling options. For more background, see:
#   https://cloud.google.com/appengine/docs/flexible/go/configuring-your-app-with-app-yaml

# TODO(dev): adjust CPU and memory based on actual requirements.
resources:
  cpu: 2
  # Instances support between [(cpu * 0.9) - 0.4, (cpu * 6.5) - 0.4]
  # Actual memory available is exposed via GAE_MEMORY_MB environment variable.
  # Recent observation with 20 workers per instance hovers around 1.5 GB.
  memory_gb: 3

  # TODO - Adjust once we understand requirements.
  disk_size_gb: 10

automatic_scaling:
  # This is intended for batch jobs.  A single instance is required, and we allow
  # it to scale up to 40 instances to get work done quickly.  However, note that
  # more than 3 tasks/sec may result in bigquery stream quota problems, so this
  # may require changes.
  min_num_instances: 10  # Too small a number here, and error rate prevents auto-scaling
  max_num_instances: 40
  # Very long cool down period, to reduce the likelihood of tasks being truncated.
  cool_down_period_sec: 1800
  # We don't care much about latency, so a high utilization is desireable.
  cpu_utilization:
    target_utilization: 0.70

# Note: add a public port for GCE auto discovery by prometheus.
# TODO(dev): are any values redundant or irrelevant?
network:
  instance_tag: etl-parser
  name: default
  # Forward port 9090 on the GCE instance address to the same port in the
  # container address. Only forward TCP traffic.
  # Note: the default AppEngine container port 8080 cannot be forwarded.
  forwarded_ports:
    - 9090/tcp

env_variables:
  # These should be substituted in the travis deployment script.
  RELEASE_TAG: ${TRAVIS_TAG}
  COMMIT_HASH: ${TRAVIS_COMMIT}

  NDT_BATCH: 'true'  # Allow instances to discover they are NDT_BATCH instances.
  MAX_WORKERS: 15  # 12 is good for NDT, but 20 is good for SS.
  BIGQUERY_PROJECT: ${INJECTED_PROJECT}
  BIGQUERY_DATASET: 'batch'
  ANNOTATE_IP: 'true'
  NDT_OMIT_DELTAS: 'true'
  # TODO add custom service-account, instead of using default credentials.
