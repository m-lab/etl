# Should be auto-deployed to sandbox and staging.
# Use github release to trigger deployment to prod.

runtime: custom
env: flex
service: etl-batch-parser

# Resource and scaling options. For more background, see:
#   https://cloud.google.com/appengine/docs/flexible/go/configuring-your-app-with-app-yaml

# TODO(dev): adjust CPU and memory based on actual requirements.
resources:
  cpu: 4
  # Instances support between [(cpu * 0.9) - 0.4, (cpu * 6.5) - 0.4]
  # Actual memory available is exposed via GAE_MEMORY_MB environment variable.
  # NOTE:
  # * for low capacity: 8
  # * for high capacity: 15
  memory_gb: 15

  # TODO - Adjust once we understand requirements.
  disk_size_gb: 10

automatic_scaling:
  # This is intended for batch jobs.
  # NOTE:
  # * for low capacity: 4, 12
  # * for high capacity: 20, 80
  min_num_instances: 20
  max_num_instances: 80
  # Very long cool down period, to reduce the likelihood of tasks being truncated.
  cool_down_period_sec: 1800
  # We don't care much about latency, so a high utilization is desireable.
  cpu_utilization:
    target_utilization: 0.50

# Note: add a public port for GCE auto discovery by prometheus.
# TODO(dev): are any values redundant or irrelevant?
network:
  instance_tag: etl-parser
  name: default
  # Forward port 9090 on the GCE instance address to the same port in the
  # container address. Only forward TCP traffic.
  # Note: the default AppEngine container port 8080 cannot be forwarded.
  forwarded_ports:
    - 9090/tcp

env_variables:
  PROMETHEUSX_LISTEN_ADDRESS: ':9090' # Must match one of the forwarded_ports above.
  BATCH_SERVICE: 'true'   # Allow instances to discover they are BATCH instances.
  MAX_WORKERS: 20
  BIGQUERY_PROJECT: ''  # Overrides GCLOUD_PROJECT
  # BIGQUERY_DATASET: 'base_tables' # Overrided computed dataset.
  NDT_OMIT_DELTAS: 'false'
  # TODO add custom service-account, instead of using default credentials.

  ANNOTATOR_URL: "{{ANNOTATOR_URL}}"
