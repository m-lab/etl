# Should be auto-deployed to sandbox and staging.
# Use github release to trigger deployment to prod.

runtime: custom
env: flex
service: etl-batch-parser

# Resource and scaling options. For more background, see:
#   https://cloud.google.com/appengine/docs/flexible/go/configuring-your-app-with-app-yaml

# TODO(dev): adjust CPU and memory based on actual requirements.
resources:
  cpu: 2
  # Instances support between [(cpu * 0.9) - 0.4, (cpu * 6.5) - 0.4]
  # Actual memory available is exposed via GAE_MEMORY_MB environment variable.
  # Recent observation with 20 workers per instance hovers around 1.5 GB.
  memory_gb: 3

  # TODO - Adjust once we understand requirements.
  disk_size_gb: 10

automatic_scaling:
  # This is intended for batch jobs.
  min_num_instances: 20
  max_num_instances: 250
  # Very long cool down period, to reduce the likelihood of tasks being truncated.
  cool_down_period_sec: 1800
  # We don't care much about latency, so a high utilization is desireable.
  cpu_utilization:
    target_utilization: 0.70

# Note: add a public port for GCE auto discovery by prometheus.
# TODO(dev): are any values redundant or irrelevant?
network:
  instance_tag: etl-parser
  name: default
  # Forward port 9090 on the GCE instance address to the same port in the
  # container address. Only forward TCP traffic.
  # Note: the default AppEngine container port 8080 cannot be forwarded.
  forwarded_ports:
    - 9090/tcp

env_variables:
  # These should be substituted in the travis deployment script.
  RELEASE_TAG: ${TRAVIS_TAG}
  COMMIT_HASH: ${TRAVIS_COMMIT}

  BATCH_SERVICE: 'true'   # Allow instances to discover they are BATCH instances.
  MAX_WORKERS: 15
  BIGQUERY_PROJECT: '${INJECTED_PROJECT}'  # Overrides GCLOUD_PROJECT
  # BIGQUERY_DATASET: 'base_tables' # Overrided computed dataset.
  ANNOTATE_IP: 'true'
  NDT_OMIT_DELTAS: 'true'
  # TODO add custom service-account, instead of using default credentials.
